{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-01-29T13:20:38.084257Z",
     "start_time": "2026-01-29T13:20:38.080685Z"
    }
   },
   "source": [
    "import os\n",
    "import math\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "from src.gpt2 import GPT2, GPT2Config"
   ],
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-29T13:20:38.093509Z",
     "start_time": "2026-01-29T13:20:38.088422Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ],
   "id": "d5711cecf10e3d41",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-29T13:20:39.767841Z",
     "start_time": "2026-01-29T13:20:38.104220Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ckpt_path = r\"C:\\workspace\\GPT2\\models\\ckpt_step6000.pt\"\n",
    "ckpt = torch.load(ckpt_path, map_location=device)\n",
    "\n",
    "ckpt.keys()"
   ],
   "id": "352be0b8a419958e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['step', 'config', 'model_state', 'optim_state'])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-29T13:20:40.932716Z",
     "start_time": "2026-01-29T13:20:39.771805Z"
    }
   },
   "cell_type": "code",
   "source": [
    "config = GPT2Config(**ckpt[\"config\"])\n",
    "model = GPT2(config).to(device)\n",
    "model.load_state_dict(ckpt[\"model_state\"])\n",
    "model.eval()"
   ],
   "id": "f9fbdf4b03b4eac8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2(\n",
       "  (wte): Embedding(50257, 768)\n",
       "  (wpe): Embedding(512, 768)\n",
       "  (drop): Dropout(p=0.1, inplace=False)\n",
       "  (h): ModuleList(\n",
       "    (0-11): 12 x Block(\n",
       "      (ln_1): LayerNorm()\n",
       "      (attn): CausalSelfAttention(\n",
       "        (c_attn): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (c_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (attn_drop): Dropout(p=0.1, inplace=False)\n",
       "        (resid_drop): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ln_2): LayerNorm()\n",
       "      (mlp): MLP(\n",
       "        (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (ln_f): LayerNorm()\n",
       "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-29T13:20:40.940918Z",
     "start_time": "2026-01-29T13:20:40.937536Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Loaded step:\", ckpt[\"step\"])\n",
    "print(\"Model device:\", next(model.parameters()).device)"
   ],
   "id": "1223a9aac3e6f7b4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded step: 6000\n",
      "Model device: cuda:0\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-29T13:20:41.757676Z",
     "start_time": "2026-01-29T13:20:40.951456Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\", local_files_only=False)\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ],
   "id": "fb4587f6f5259e8d",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-29T13:20:41.772697Z",
     "start_time": "2026-01-29T13:20:41.761186Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x = torch.randint(\n",
    "    low=0,\n",
    "    high=config.vocab_size,\n",
    "    size=(2, 32),\n",
    "    device=device\n",
    ")\n",
    "\n",
    "with torch.no_grad():\n",
    "    logits, loss = model(x, x)\n",
    "\n",
    "logits.shape, loss.item()"
   ],
   "id": "e32b19b829135ee5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 32, 50257]), 14.503641128540039)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-29T13:20:41.779769Z",
     "start_time": "2026-01-29T13:20:41.776869Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def eval_text(model, tokenizer, text):\n",
    "    model.eval()\n",
    "    enc = tokenizer(text, return_tensors=\"pt\")\n",
    "    idx = enc[\"input_ids\"].to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        _, loss = model(idx, idx)\n",
    "\n",
    "    ppl = math.exp(loss.item())\n",
    "    return loss.item(), ppl"
   ],
   "id": "47c0a35e0b616adb",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-29T13:20:41.796075Z",
     "start_time": "2026-01-29T13:20:41.781637Z"
    }
   },
   "cell_type": "code",
   "source": [
    "text = \"In the beginning, the universe was\"\n",
    "loss, ppl = eval_text(model, tokenizer, text)\n",
    "loss, ppl"
   ],
   "id": "618cc75873ef50ba",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10.439993858337402, 34200.442389666554)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-29T13:20:41.804047Z",
     "start_time": "2026-01-29T13:20:41.800340Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@torch.no_grad()\n",
    "def generate(\n",
    "    model,\n",
    "    tokenizer,\n",
    "    prompt,\n",
    "    max_new_tokens=100,\n",
    "    temperature=0.8,\n",
    "    top_k=50\n",
    "):\n",
    "    model.eval()\n",
    "    idx = tokenizer(prompt, return_tensors=\"pt\")[\"input_ids\"].to(device)\n",
    "\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:, -model.config.block_size:]\n",
    "        logits, _ = model(idx_cond)\n",
    "\n",
    "        logits = logits[:, -1, :] / temperature\n",
    "\n",
    "        if top_k is not None:\n",
    "            v, _ = torch.topk(logits, top_k)\n",
    "            logits[logits < v[:, [-1]]] = -float(\"inf\")\n",
    "\n",
    "        probs = F.softmax(logits, dim=-1)\n",
    "        next_id = torch.multinomial(probs, num_samples=1)\n",
    "\n",
    "        idx = torch.cat([idx, next_id], dim=1)\n",
    "\n",
    "    return tokenizer.decode(idx[0], skip_special_tokens=True)"
   ],
   "id": "a3e5e1f23ab62e43",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-29T13:22:00.956352Z",
     "start_time": "2026-01-29T13:22:00.182494Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(generate(\n",
    "    model,\n",
    "    tokenizer,\n",
    "    prompt=\"I'm trying to say hello\",\n",
    "    max_new_tokens=120,\n",
    "    temperature=0.9,\n",
    "    top_k=40\n",
    "))"
   ],
   "id": "8b866f1b56c81ee",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm trying to say hello that it is a teenager on a trip where he was a former film film for its sequel . \n",
      " = = Personal life = = \n",
      " Following his career , he was appointed as a strong pitcher in March 1935 . He was promoted to England , and won the Royal Australian National Museum of California . The last league career , he made his first career career career at West Yorkshire and was in January 1936 , and it won the Order of California at Cardiff 's School . He later participated in the South Australian Royal Marine Artillery , and three hits at Oxford University College . He attended\n"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-29T13:20:42.446633Z",
     "start_time": "2026-01-29T13:20:42.444617Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "8afeda535ee41120",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
